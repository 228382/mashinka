Тема ML1 регрессия
::функция ошибки::выберете верные утверждения{
    ~%50% Функция ошибки показывает численно, насколько модель хорошо описывает данные.
    ~%0% Аргументами функции ошибки являются параметры модели, но ошибка не зависит от них.
    ~%0% Вид функции ошибки не определяет то, какой вид регрессии реализуется.
    ~%0% Цель алгоритма машинного обучения - найти такой набор параметров модели, при которых ошибка максимальна.
    ~%50% Само значение функции ошибки не несет никакого смысла, оно используется только в сравнении.
}

Тема ML1 регрессия
::модель лр:: Модель линейной регрессии использует функцию ошибки:{
    ~%100% Mean Squared Error (MSE).
    ~%0% Root Mean Squared Error (RMSE).
    ~%0% Mean Absolute Error (MAE).
    ~%0% Log Loss.
    ~%0% Cross Entropy Loss.

Тема ML1 регрессия
::MSE и MAE:: Почему выбираются функции ошибки MSE и MAE для регрессионных моделей:{
    ~%33% Они учитывают разницу между предсказанными и фактическими значениями.
    ~%33% Они позволяют оценить точность модели в числовом выражении.
    ~%33% Устойчивы к выбросам в данных.
    ~%0% Позволяют проводить классификацию объектов.
    ~%0% Используются только для ускорения процесса обучения модели.
}
 
Тема ML1 регрессия
::градиентный спуск::выберете верные утверждения{
    ~%50% Он может использоваться для минимизации функции потерь в обучении моделей машинного обучения.
    ~%0% Метод градиентного спуска работает только для линейных моделей.
    ~%50% Использует производные функции для определения направления движения к минимуму.
    ~%0% Всегда гарантирует нахождение глобального минимума.
    ~%0% Метод градиентного спуска не подходит для задач классификации.
}

Тема ML1 регрессия
::мр и пр::отличия множественная регрессии от парной{
    ~%0% Множественная регрессия использует только одну независимую переменную.
    ~%0% Парная регрессия использует только одну зависимую переменную.
    ~%100% Множественная регрессия использует несколько независимых переменных.
    ~%0% Парная регрессия использует несколько зависимых переменных.
    ~%0% Множественная регрессия не отличается от парной.
}
 
 
Тема ML1 регрессия
::нормализация признаков::выберете верные утверждения{
    ~%0% Даже без нормализации пирзнаков, нарушение баланса между влиянием входных переменных, представленных в разных масштабах, на выходную переменную не возникнет.
    ~%0% Нормализация признаков ухудшает процесс работы с моделью.
    ~%33% Нормализация нужна для ускорения метода градиентного спуска.
    ~%33% Параметры нормализации высчитываются по обучающей выборке.
    ~%33% Если исходный диапазон мал и его изменчивость очень низкая, что плохо сказывается на качестве построенной модели, то решить проблему можно путём применения минимаксной нормализации.
        ~%33% Недостаткам минимаксной нормализации является наличие аномальных значений данных, которые «растягивают» диапазон, что приводит к тому, что нормализованные значения опять же концентрируются в некотором узком диапазоне вблизи нуля.
}
 
Тема ML1 регрессия
::задачи регрессии:: Из приведенных примеров укажите те, которые являются задачами регрессии:{
    ~%50% Прогнозирование цены недвижимости по ее характеристикам.
    ~%0% Классификация изображений на котов и собак
    ~%0% Определение вероятности оттока клиентов
    ~%50% Предсказание уровня загрязнения воздуха по метеоданным
    ~%0% Определение типа цветка по его размерам
}

Тема ML1 регрессия
::объект лр:: объект линейной регрессии имеет: атрибуты{
    ~%0% classes_ - классы в задаче классификации.
    ~%100% coef_ - коэффициенты модели.
    ~%0% intercept_ - свободный член модели.
    ~%0% feature_importances_ - важность признаков.
    ~%0% n_iter_ - количество итераций обучения.
}
 
Тема ML1 регрессия
::коэфициенты лр:: физический смысл коэфициентов линейной регрессии:{
    ~%100% Показывают силу взаимосвязи между переменными.
    ~%0% Показывают вероятность события.
    ~%0% Оопределяют точность модели.
    ~%0% Показывают разброс данных.
    ~%0% Не имеют физического смысла.
}

Тема ML1 регрессия
::скорость обучения:: Верные  утверждения относительно скорости обучения:{
    ~%33% Большая скорость обучения может привести к расхождению алгоритма.
    ~%33% Маленькая скорость обучения может замедлить сходимость алгоритма.
    ~%33% Оптимальная скорость обучения зависит от конкретной задачи и данных.
    ~%0% Скорость обучения не имеет значения при использовании метода градиентного спуска.
    ~%0% Скорость обучения должна быть постоянной на протяжении всего процесса обучения.
}

Тема ML1 регрессия
::график обучения:: Зачем строить график обучения:{
    ~%0% Для оценки мощности сходимости алгоритма.
    ~%33% Для определения оптимального количества эпох обучения.
    ~%33% Для визуального представления процесса обучения.
    ~%33% Для выявления переобучения или недообучения модели.
    ~%0% Для усложнения процесса обучения.
}

Тема ML1 регрессия
::метрики эффективности::  метрики эффективности можно применять для оценки регрессионных моделей:{
    ~%0% Accuracy.
    ~%0% Precision.
    ~%0% Recall.
    ~%0% F1 Score.
    ~%100% R-squared.
}

Тема ML1 регрессия
::значение ошибки:: Верные утверждения относительно значения ошибки регрессии:{
    ~%50% Чем меньше значение ошибки, тем лучше модель выполняет предсказания.
    ~%0% Значение ошибки всегда должно быть равно нулю.
    ~%0% Значение ошибки не зависит от выбора функции потерь.
    ~%50% Значение ошибки не может быть отрицательным.
    ~%0% Значение ошибки не имеет значения для оценки качества модели.
}

Тема ML1 регрессия
::данные мо:: Данные для модели машинного обучения должны выглядеть:{
    ~%0% Только числовые значения.
    ~%0% Только категориальные значения.
    ~%100% Как числовые, так и категориальные значения.
    ~%0% Текстовые значения.
    ~%0% Только изображения.
}

Тема ML1 регрессия
::предсказанные значения:: Для визуализации модели нельзя использовать предсказанные значения по датасету потому, что:{
    ~%100% Предсказанные значения могут быть неверными из-за переобучения модели.
    ~%0% Предсказанные значения могут быть неверными из-за недообучения модели.
    ~%0% Предсказанные значения могут быть неверными из-за выбросов в данных.
    ~%0% Предсказанные значения могут быть неверными из-за неправильного выбора модели.
    ~%0% Предсказанные значения всегда верны для визуализации модели.
}

Тема ML1 регрессия
::модели регрессии:: Применение разных моделей регрессии в библиотеке sklearn отличается от моделей классификации:{
    ~%0% Регрессия использует функцию ошибки MSE, а классификация использует функцию ошибки LogLoss.
    ~%0% Регрессия работает с категориальными признаками, а классификация с числовыми.
    ~%100% Регрессия предсказывает непрерывный результат, а классификация предсказывает категорию .
    ~%0% Регрессия не требует нормализации данных, а классификация требует.
    ~%0% Регрессия не может использовать регуляризацию, в отличие от классификации.
}


Тема ML1 регрессия
::R^2:: коэффициент детерминации для модели регрессии показывает:{
    ~%0% Долю правильных ответов.
    ~%0% Стандартную ошибку оценки.
    ~%0% Уровень значимости коэффициентов.
    ~%0% Количество признаков в модели.
    ~%100% Степень связи между зависимой и независимыми переменными .
}

Тема ML1 регрессия
::коэффициенты линейной регрессии:: Коэффициенты линейной регрессии имеют значение :{
    ~%0% Они показывают количество выбросов в данных.
    ~%0% Показывают стандартную ошибку оценки.
    ~%0% Они показывают уровень значимости модели.
    ~%100% Показывают степень влияния каждого признака на целевую переменную.
    ~%0% Показывают распределение ошибок модели.
}

Тема ML2 классификация
::задачи классификации:: Из приведенных примеров укажите те, которые являются задачами классификации{
    ~%100% Предсказание вероятности события, например, вероятность выигрыша команды в футбольном матче.
    ~%0% Предсказание цены дома на основе его характеристик.
    ~%0% Определение типа цветка по его размерам и форме.
    ~%0% Классификация писем как спам или не спам.
    ~%0% Распознавание лиц на фотографии.
}

Тема ML2 классификация
::шаг градиентного спуска:: определение шаа градиентного спуска{
    ~%0% Количество итераций обучения.
    ~%100% Величина изменения коэффициентов модели на каждой итерации обучения.
    ~%0% Скорость обучения модели.
    ~%0% Размер мини-пакета в методе стохастического градиентного спуска.
    ~%0% Величина изменения функции ошибки на каждой итерации обучения.
}

Тема ML2 классификация
::логарифмическая функция потерь:: функция, которая используется в качестве функции ошибки в модели логистической регресси{
    ~%0% MSE.
    ~%0% MAE.
    ~%100% LogLoss .
    ~%0% RMSE.
    ~%0% MAPE.
}

Тема ML2 классификация
::реализация лог регрессии:: при реализации логистической регрессии к матрице признаков добавлялся столбец из единиц по причине{
    ~%0% Для уменьшения переобучения модели.
    ~%0% Для улучшения качества предсказаний.
    ~%0% Для увеличения скорости обучения модели.
    ~%100% Для устранения мультиколлинеарности.
    ~%0% Для уменьшения сложности модели.
}

Тема ML2 классификация
::метрика точности:: метрика точности регрессии показывает{
    ~%0% Степень связи между зависимой и независимыми переменными.
    ~%0% Количество признаков в модели.
    ~%0% Уровень значимости коэффициентов.
    ~%0% Стандартную ошибку оценки.
    ~%100% Долю правильных ответов.
}

Тема ML2 классификация
::объект логистической регрессии:: объект логистической регрессии имеет атрибуты{
    ~%100% coef_ - коэффициенты модели.
    ~%0% intercept_ - свободный член модели.
    ~%0% feature_importances_ - важность признаков.
    ~%0% classes_ - классы в задаче классификации.
    ~%0% n_iter_ - количество итераций обучения.
}

Тема ML2 классификация
::коэффициенты логистической регрессии:: коэффициенты логистической регрессии имеют значение{
    ~%100% Они показывают вероятность принадлежности к классу.
    ~%0% Показывают степень влияния каждого признака на целевую переменную.
    ~%0% Они показывают распределение ошибок модели.
    ~%0% Показывают уровень значимости модели.
    ~%0% Показывают количество выбросов в данных.
}

Тема ML2 классификация
::моделей машинного обучения:: параметры и атрибуты в объектах других моделей машинного обучения библиотеки sklearn{
    ~%0% n_estimators - количество деревьев в случайном лесе.
    ~%0% max_features - максимальное количество признаков для разбиения в дереве.
    ~%0% loss - функция потерь для градиентного бустинга.
    ~%50% alpha - параметр регуляризации в Ridge регрессии.
    ~%50% criterion - критерий разделения в деревьях решений.
}

Тема ML2 классификация
::матрица классификации:: матрица классификации показывет{
    ~%0% Долю правильных ответов для каждого класса.
    ~%0% Матрицу корреляции признаков.
    ~%100% Долю правильных ответов и ошибок для каждого класса.
    ~%0% Уровень значимости коэффициентов.
    ~%0% Количество признаков в модели.
}

Тема ML2 классификация
::конструктор объекта логистической регрессии:: конструктор объекта логистической регрессии имеет параметры{
    ~%0% n_iter - количество итераций обучения.
    ~%0% learning_rate - скорость обучения модели.
    ~%100% penalty - тип регуляризации.
    ~%0% criterion - критерий останова обучения.
    ~%0% max_depth - максимальная глубина дерева.
}

Тема ML3 полиномиальные модели
::метод множественной регрессии:: суть метода множественной регрессии{
    ~%0% В построении нескольких моделей для разных классов задачи классификации.
    ~%100% В использовании нескольких признаков для предсказания целевой переменной .
    ~%0% В учете неопределенности предсказаний модели.
    ~%0% В использовании нескольких метрик для оценки качества модели.
    ~%0% В учете взаимодействия между признаками.
}

Тема ML3 полиномиальные модели
::полиномиальные признаки:: введение полиномиальных признаков может быть полезным в случаях{
    ~%100% Когда данные уже содержат высокую степень нелинейности.
    ~%0% Когда данные линейно разделимы.
    ~%0% Когда данные содержат большое количество выбросов.
    ~%0% Когда данные имеют высокую корреляцию между признаками.
    ~%0% Когда данные имеют нормальное распределение.
}

Тема ML3 полиномиальные модели
::комбинации атрибутов:: при введении полиномиальных признаков нужно добавить все комбинации атрибутов до заданной степени по причине{
    ~%0% Для уменьшения переобучения модели.
    ~%0% Для устранения мультиколлинеарности.
    ~%0% Для увеличения скорости обучения модели.
    ~%0% Для улучшения интерпретируемости модели.
    ~%100% Для уменьшения сложности моделие.
}

Тема ML3 методы обучения с учителем
::SVC и LinearSVC:: отличия классов SVC и LinearSVC в библиотеке sklearn при использовании метода опорных векторов без ядра{
    ~%100% SVC использует ядро, а LinearSVC не использует.
    ~%0% LinearSVC использует ядро, а SVC не использует.
    ~%0% Оба класса используют ядро.
    ~%0% Оба класса не используют ядро.
    ~%0% Оба класса используют регуляризацию.
}

Тема ML3 методы обучения с учителем
::функция ядра:: влияние выбора функции ядра на форму границы принятия решения{
    ~%0% Ядро определяет количество классов.
    ~%100% Ядро определяет, как данные будут проецироваться в пространство большей размерности .
    ~%0% Ядро определяет количество признаков.
    ~%0% Ядро определяет коэффициент регуляризации.
    ~%0% Ядро определяет скорость обучения.
}

Тема ML3 методы обучения с учителем
::метод опорных векторов:: работа метода опорных векторов в задачах множественной классификации{
    ~%0% Он разделяет данные на два класса.
    ~%100% Строит несколько гиперплоскостей для разделения нескольких классов.
    ~%0% Не может быть использован для множественной классификации.
    ~%0% Применяется только для регрессии.
    ~%0% Строит кривые для разделения классов.
}

Тема ML3 методы обучения с учителем
::использлвание метода ов:: Чем метод опорных векторов может быть использован для решения задачи регрессии{
    ~%0% Использует градиентный спуск для поиска оптимальных параметров.
    ~%0% Строит линейную регрессию.
    ~%100% Ищет оптимальную гиперплоскость, которая минимизирует ошибку предсказания.
    ~%0% Применяет L1-регуляризацию.
    ~%0% Применяет L2-регуляризацию.
}

Тема ML3 методы обучения с учителем
::глубокая нейронная сеть:: определение глубокой нейронной сетьи{
    ~%0% Нейронная сеть, использующая функцию активации ReLU.
    ~%0% Нейронная сеть с одним слоем.
    ~%0% Нейронная сеть, использующая функцию активации сигмоиды.
    ~%0% Нейронная сеть, обученная на большом объеме данных.
    ~%100% Нейронная сеть с большим количеством слоев.
}

Тема ML3 методы обучения с учителем
::архитектура нс:: архитектура нейронной сети это{
    ~%0% Количество нейронов в сети.
    ~%0% Количество слоев в сети.
    ~%0% Размеры входных и выходных слоев.
    ~%100% Структура и соединения между нейронами.
    ~%0% Функции активации, используемые в сети.
}

Тема ML3 методы обучения с учителем
::качество моделирования:: укажите как количество нейронов и слоев влияет на качество моделирования{
    ~%0% Меньшее количество нейронов и слоев всегда улучшает качество модели.
    ~%100% Большее количество нейронов и слоев всегда улучшает качество модели .
    ~%0% Количество нейронов не влияет на качество моделирования.
    ~%0% Влияние зависит от конкретной задачи и данных.
    ~%0% Количество слоев не влияет на качество моделирования.
}

Тема ML3 методы обучения с учителем
::нейронная сеть:: укажите как нейронная сеть решает задачи множественной классификации{
    ~%100% Использует softmax-функцию на выходном слое.
    ~%0% Использует функцию активации сигмоиды для каждого класса.
    ~%0% Использует только один выходной нейрон для всех классов.
    ~%0% Использует функцию активации ReLU для каждого класса.
    ~%0% Использует только один скрытый слой.
}

Тема ML3 методы обучения с учителем
::перцептрон:: перцептрон следует применять в случаях{
    ~%0% Для задач регрессии.
    ~%0% Для задач множественной классификации.
    ~%100% Для линейно разделимых данных.
    ~%0% Для нелинейно разделимых данных.
    ~%0% Для больших объемов данных.
}

Тема ML3 дерево решений
::дерево решений:: граница принятия решений у деревьев решений имеет такую характерную форму по причине{
    ~%0% Это связано с особенностями алгоритма работы дерева решений.
    ~%0% Она формируется на основе структуры данных, используемых в модели.
    ~%100% Это результат оптимизации модели для минимизации ошибок прогнозирования.
    ~%0% Такая форма границы принятия решений обусловлена математической моделью, лежащей в основе дерева решений.
    ~%0% Граница принятия решений формируется на основе случайно выбранных признаков.
}

Тема ML3 дерево решений
::глубина дерева:: влияние глубины дерева на сложность модели{
    ~%0% Процесс обучения модели становится более ресурсоемким.
    ~%0% При увеличении глубины дерева возможно переобучение модели.
    ~%50% С увеличением глубины дерева сложность модели увеличивается.
    ~%0% Глубина дерева не влияет на сложность модели.
    ~%50% Модель становится более интерпретируемой при увеличении глубины дерева.
}

Тема ML3 дерево решений
::разная глубина дерева:: глубина дерева на разных ветках может быть разная по причине{
    ~%0% Это зависит от входных данных, использованных для обучения модели.
    ~%50% Размер выборки, используемой для обучения, влияет на разную глубину дерева на разных ветках.
    ~%0% Это результат случайного процесса при обучении модели.
    ~%50% Глубина дерева на разных ветках может быть разной только при использовании определенных критериев.
    ~%0% Глубина дерева на разных ветках всегда одинаковая.
}

Тема ML3 дерево решений
::критерий в деревьях:: критерий в деревьях решений и то, как он влияет на работу модели{
    ~%50% Критерий - это функция, используемая для измерения качества разделения на каждом узле дерева.
    ~%0% Выбор критерия влияет на сложность модели и время обучения.
    ~%0% Выбор критерия не оказывает влияния на работу модели.
    ~%0% Все критерии дают одинаковые результаты при построении дерева решений.
    ~%50% Каждый критерий решает задачу классификации или регрессии.
}